import json
import urllib.request
import urllib.parse
import time
import traceback

#https://quote.eastmoney.com/center/gridlist.html#hs_a_board
LIST_URL = "https://push2.eastmoney.com/api/qt/clist/get" 

PARAMS = {
    "np": 1,
    "fltt": 1,
    "invt": 2,
    "fs": (
        "m:0+t:6+f:!2,"
        "m:0+t:80+f:!2,"
        "m:1+t:2+f:!2,"
        "m:1+t:23+f:!2,"
        "m:0+t:81+s:262144+f:!2"
    ),
    "fields": (
        "f12,f13,f14,f1,f2,f4,f3,f152,f5,f6,f7,"
        "f15,f18,f16,f17,f10,f8,f9,f23"
    ),
    "fid": "f3",
    "po": 1,
    "dect": 1,
    "ut": "fa5fd1943c7b386f172d6893dbfba10b",
    "wbp2u": "|0|0|0|web",
    "pz": 100,   # æ¯é¡µ 200ï¼ˆå®‰å…¨å€¼ï¼‰
}

HEADERS = {
    "User-Agent": "Mozilla/5.0",
    "Accept": "*/*",
}

def fetch_page(page):
    params = PARAMS.copy()
    params["pn"] = page

    url = LIST_URL + "?" + urllib.parse.urlencode(params)
    req = urllib.request.Request(url, headers=HEADERS)

    with urllib.request.urlopen(req, timeout=10) as resp:
        text = resp.read().decode("utf-8")

    # æ¥å£å¯èƒ½è¿”å› JSON æˆ– JSONP
    if text.startswith("{"):
        data = json.loads(text)
    else:
        # JSONP: cb({...})
        start = text.find("(") + 1
        end = text.rfind(")")
        data = json.loads(text[start:end])

    return data["data"]

# https://quote.eastmoney.com/sz002163.html
KLINE_URL = "https://push2his.eastmoney.com/api/qt/stock/kline/get"

def fetch_all_stocks():
    all_rows = []
    # page = 54
    page = 1

    while True:
        data = fetch_page(page)
        if not data:
            break
        diff = data.get("diff", [])

        if not diff:
            break

        all_rows.extend(diff)

        print(f"å·²æ‹‰å–ç¬¬ {page} é¡µï¼Œç´¯è®¡ {len(all_rows)} æ¡")

        if page >= data.get("total", 1):
            break

        page += 1
        time.sleep(0.2)  # é˜²æ­¢è¿‡å¿«

    return all_rows


def parse_jsonp(text, callback_prefix="jsonp1767611448796"):
    """
    å®‰å…¨è§£æ JSONP è¿”å›çš„æ–‡æœ¬ï¼Œè¿”å› dict
    """
    # æ‰¾åˆ°å¼€å¤´ "("
    start = text.find(callback_prefix + "(")
    if start >= 0:
        start += len(callback_prefix) + 1  # è·³è¿‡ callback(
        end = text.rfind(")")               # å»æ‰æœ€åçš„ )
        text = text[start:end]

    text = text.strip()  # å»æ‰å¤šä½™ç©ºæ ¼æˆ–æ¢è¡Œ
    return json.loads(text)

def fetch_ma10(secid, max_bars=40):
    params = {
        "fields1": "f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13",
        "fields2": "f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61",
        "beg": 0,
        "end": 20500101,
        "ut": "fa5fd1943c7b386f172d6893dbfba10b",
        "rtntype": 6,
        "secid": secid,
        "klt": 101,
        "fqt": 1,
        "cb": "callback123",  # JSONP å›è°ƒï¼Œå¯ä»¥éšä¾¿å†™
    }

    url = KLINE_URL + "?" + urllib.parse.urlencode(params)
    req = urllib.request.Request(url, headers=HEADERS)
    with urllib.request.urlopen(req, timeout=10) as r:
        text = r.read().decode()

    # å»æ‰ JSONP
    # print(text)
    data = parse_jsonp(text, "callback123")
    klines = data.get("data", {}).get("klines", [])

    # åªä¿ç•™æœ€è¿‘ max_bars æ ¹
    klines = klines[-max_bars:]

    closes = [] # æ”¶ç›˜ä»·
    volumes = [] # æˆäº¤é‡
    lows = [] # æœ€ä½ä»·
    pcts = [] # æ¶¨è·Œåœ
    for k in klines:
        parts = k.split(",")
        if len(parts) < 6:
            continue

        close = parts[2]   # æ”¶ç›˜ä»·
        vol = parts[5]     # æˆäº¤é‡
        low = parts[4]
        pct = parts[8]

        if close in ("", "-") or vol in ("", "-"):
            continue

        try:
            closes.append(float(close))
            volumes.append(float(vol))
            lows.append(float(low))
            pcts.append(float(pct))
        except ValueError:
            continue
    
    def ma(n):
        return sum(closes[-n:]) / n if len(closes) >= n else None

    
    ma10 = ma(10)
    ma20 = ma(20)
    ma30 = ma(30)
    vol_today = volumes[-1]
    vol_ma10 = sum(volumes[-10:]) / 10
    low_today = lows[-1]

    recent_pcts = pcts[-20:] if len(pcts) >= 20 else pcts
    has_limit_up = any(pct >= 9.8 for pct in recent_pcts)

    return {
        "ma10": ma10,
        "ma20": ma20,
        "ma30": ma30,
        "vol_today": vol_today,
        "vol_ma10": vol_ma10,
        "low_today": low_today,
        "has_limit_up": has_limit_up
    }

def to_float(v):
    try:
        return float(v)
    except (TypeError, ValueError):
        return None
    
def has_recent_limit_up(klines, min_days=5, max_days=20):
    for i in range(-max_days, -min_days):
        pct = float(klines[i].split(",")[8])
        if pct >= 9.8:
            return True
    return False

    
if __name__ == "__main__":
    stocks = fetch_all_stocks()
    print(f"å…¨å¸‚åœºè‚¡ç¥¨æ•°ï¼š{len(stocks)}")

    # ğŸ‘‰ æ ¸å¿ƒï¼šåªç­›ä¸‹è·Œçš„
    down_stocks = [
        s for s in stocks  
        if to_float(s["f3"]) is not None
          and to_float(s["f3"]) < 0
          and to_float(s["f2"]) is not None
          and to_float(s["f2"])/100 <= 50
          and not (s.get("f14","").upper().startswith("ST") or s.get("f14","").upper().startswith("*ST"))

    ]

    print(f"å½“å‰ä¸‹è·Œè‚¡ç¥¨æ•°ï¼š{len(down_stocks)}\n")

    # æ‰“å°å‰ 20 æ¡çœ‹çœ‹
    # for s in down_stocks[:20]:
    #     print(
    #         f"{s['f12']} {s['f14']:<6} "
    #         f"ç°ä»·:{s['f2']/100} "
    #         f"æ¶¨è·Œå¹…:{s['f3']/100}%"
    #     )

    # ç­›é€‰é è¿‘ MA10 1.03 çš„è‚¡ç¥¨
    result = []
    for s in down_stocks:
        secid = f"{s['f13']}.{s['f12']}"
        try:
            # info = fetch_ma10("0.002598")
            info = fetch_ma10(secid)
            if info is None or info["ma10"] or info["ma20"] or info["ma30"] is None:
                continue
            
            is_shrinking = info["vol_today"] / info["vol_ma10"] < 0.7
            ratio = s["f2"]/100 / info["ma10"]

            # å½±çº¿ä¸èƒ½å¤ªå¤¸å¼ 
            is_good_pullback = (info["ma10"] - info["low_today"]) / info["ma10"] < 0.03

            if is_shrinking and is_good_pullback:
              print(
                  f"{s['f12']} {s['f14']:<6}\t"
                  f"ç°ä»·:{s['f2']/100}\t"
                  f"æ¶¨è·Œå¹…:{s['f3']/100}%\t"
                  f"10æ—¥çº¿:{round(info["ma10"], 2)}\t"
                  f"ç¼©é‡:{is_shrinking}\t"
                  f"ratio:{round(ratio,3)}\t"
              )
            if is_good_pullback and is_shrinking and info["ma10"] > info["ma20"] and info["ma20"] > info["ma30"] and ratio <= 1.04 and s["f2"]/100 > info["ma10"]:
                s.update({"ma10": round(info["ma10"],2), "ratio": round(ratio,3), "has_limit_up": info["has_limit_up"]})
                result.append(s)
        except Exception as e:
            print(f"Exception for {s['f12']}: {e}")
            traceback.print_exc()
            break
        time.sleep(0.15)  # é¿å…è¯·æ±‚è¿‡å¿«


    result.sort(key=lambda x: x.get("has_limit_up", False), reverse=True)

    print(f"\nç­›é€‰å‡ºé è¿‘ MA10 çš„è‚¡ç¥¨æ•°ï¼š{len(result)}\n")
    for s in result:
        print(
          f"{s['f12']} {s['f14']:<6}\t"
          f"ç°ä»·:{s['f2']/100}\t"
          f"æ¶¨è·Œå¹…:{s['f3']/100}%\t"
          f"10æ—¥çº¿:{round(s["ma10"], 2)}\t"
          f"ratio:{round(s['ratio'],3)}\t"
          f"è¿‘æœŸæ¶¨åœ:{s["has_limit_up"]}\t"
        )
